{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrh7C2JPOSAvdm1Ueylf0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akmal-2253/NLP-Natural-language-processing-/blob/main/NLPpython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "L0WZLbdSeW3K"
      },
      "outputs": [],
      "source": [
        "x='A paragraph (from Ancient Greek παράγραφος (parágraphos) \"to write beside\") is a self-contained unit of discourse in writing dealing with a particular point or idea. Though not required by the orthographic conventions of any language with a writing system, paragraphs are a conventional means of organizing extended segments of prose.'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WORD TOKENIZE\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "w=word_tokenize(x)\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlOpLVLReqYT",
        "outputId": "25e4aa19-5d9f-408d-bddc-8aabe77d5a92",
        "collapsed": true
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'paragraph',\n",
              " '(',\n",
              " 'from',\n",
              " 'Ancient',\n",
              " 'Greek',\n",
              " 'παράγραφος',\n",
              " '(',\n",
              " 'parágraphos',\n",
              " ')',\n",
              " '``',\n",
              " 'to',\n",
              " 'write',\n",
              " 'beside',\n",
              " \"''\",\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'self-contained',\n",
              " 'unit',\n",
              " 'of',\n",
              " 'discourse',\n",
              " 'in',\n",
              " 'writing',\n",
              " 'dealing',\n",
              " 'with',\n",
              " 'a',\n",
              " 'particular',\n",
              " 'point',\n",
              " 'or',\n",
              " 'idea',\n",
              " '.',\n",
              " 'Though',\n",
              " 'not',\n",
              " 'required',\n",
              " 'by',\n",
              " 'the',\n",
              " 'orthographic',\n",
              " 'conventions',\n",
              " 'of',\n",
              " 'any',\n",
              " 'language',\n",
              " 'with',\n",
              " 'a',\n",
              " 'writing',\n",
              " 'system',\n",
              " ',',\n",
              " 'paragraphs',\n",
              " 'are',\n",
              " 'a',\n",
              " 'conventional',\n",
              " 'means',\n",
              " 'of',\n",
              " 'organizing',\n",
              " 'extended',\n",
              " 'segments',\n",
              " 'of',\n",
              " 'prose',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "p=pos_tag(w)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTlm8s-Ufq8n",
        "outputId": "3ba50ec9-b38a-4f35-ece2-83ea7bc496b4",
        "collapsed": true
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 'DT'),\n",
              " ('paragraph', 'NN'),\n",
              " ('(', '('),\n",
              " ('from', 'IN'),\n",
              " ('Ancient', 'NNP'),\n",
              " ('Greek', 'NNP'),\n",
              " ('παράγραφος', 'NNP'),\n",
              " ('(', '('),\n",
              " ('parágraphos', 'NN'),\n",
              " (')', ')'),\n",
              " ('``', '``'),\n",
              " ('to', 'TO'),\n",
              " ('write', 'VB'),\n",
              " ('beside', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " (')', ')'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('self-contained', 'JJ'),\n",
              " ('unit', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('discourse', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('writing', 'VBG'),\n",
              " ('dealing', 'VBG'),\n",
              " ('with', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('particular', 'JJ'),\n",
              " ('point', 'NN'),\n",
              " ('or', 'CC'),\n",
              " ('idea', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Though', 'IN'),\n",
              " ('not', 'RB'),\n",
              " ('required', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('orthographic', 'JJ'),\n",
              " ('conventions', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('any', 'DT'),\n",
              " ('language', 'NN'),\n",
              " ('with', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('writing', 'NN'),\n",
              " ('system', 'NN'),\n",
              " (',', ','),\n",
              " ('paragraphs', 'NN'),\n",
              " ('are', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('conventional', 'JJ'),\n",
              " ('means', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('organizing', 'VBG'),\n",
              " ('extended', 'JJ'),\n",
              " ('segments', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('prose', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var='Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs. Working with corpora, categorizing text, analyzing linguistic structure, and more. The online version of the book has been been updated for Python 3 and NLTK 3'"
      ],
      "metadata": {
        "id": "CmHQKqWHlQ5k"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SENTENCE TOKENIZE\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "sent=sent_tokenize(var)\n",
        "sent\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJduZqLogPTH",
        "outputId": "2f90e8a1-e470-40fd-88ec-05703810812a"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural Language Processing with Python provides a practical introduction to programming for language processing.',\n",
              " 'Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs.',\n",
              " 'Working with corpora, categorizing text, analyzing linguistic structure, and more.',\n",
              " 'The online version of the book has been been updated for Python 3 and NLTK 3']"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STOP WORDS\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "nltk.download('stopwords')\n",
        "stop=stopwords.words('english')\n",
        "\n",
        "stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HnCjYwxNnQrM",
        "outputId": "338f05b1-a371-4f83-89b5-064e35765378"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_tokenize=word_tokenize(var)\n",
        "w_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gj1ukhMnrFcn",
        "outputId": "edeb7459-0272-46ca-9fa1-922b0878f78a"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'with',\n",
              " 'Python',\n",
              " 'provides',\n",
              " 'a',\n",
              " 'practical',\n",
              " 'introduction',\n",
              " 'to',\n",
              " 'programming',\n",
              " 'for',\n",
              " 'language',\n",
              " 'processing',\n",
              " '.',\n",
              " 'Written',\n",
              " 'by',\n",
              " 'the',\n",
              " 'creators',\n",
              " 'of',\n",
              " 'NLTK',\n",
              " ',',\n",
              " 'it',\n",
              " 'guides',\n",
              " 'the',\n",
              " 'reader',\n",
              " 'through',\n",
              " 'the',\n",
              " 'fundamentals',\n",
              " 'of',\n",
              " 'writing',\n",
              " 'Python',\n",
              " 'programs',\n",
              " '.',\n",
              " 'Working',\n",
              " 'with',\n",
              " 'corpora',\n",
              " ',',\n",
              " 'categorizing',\n",
              " 'text',\n",
              " ',',\n",
              " 'analyzing',\n",
              " 'linguistic',\n",
              " 'structure',\n",
              " ',',\n",
              " 'and',\n",
              " 'more',\n",
              " '.',\n",
              " 'The',\n",
              " 'online',\n",
              " 'version',\n",
              " 'of',\n",
              " 'the',\n",
              " 'book',\n",
              " 'has',\n",
              " 'been',\n",
              " 'been',\n",
              " 'updated',\n",
              " 'for',\n",
              " 'Python',\n",
              " '3',\n",
              " 'and',\n",
              " 'NLTK',\n",
              " '3']"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_word=list(punctuation)+stop"
      ],
      "metadata": {
        "collapsed": true,
        "id": "J-OHR5DLoZbp"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pXqCdifgphUd",
        "outputId": "55746224-fb5a-4f01-ca76-bb9cbe99ca0c"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['!',\n",
              " '\"',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in w_tokenize:\n",
        " if i not in stop_word:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRRipTU6rTkf",
        "outputId": "14fa0dd1-48a9-4ecb-b346-5c7c29b43043",
        "collapsed": true
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural\n",
            "Language\n",
            "Processing\n",
            "Python\n",
            "provides\n",
            "practical\n",
            "introduction\n",
            "programming\n",
            "language\n",
            "processing\n",
            "Written\n",
            "creators\n",
            "NLTK\n",
            "guides\n",
            "reader\n",
            "fundamentals\n",
            "writing\n",
            "Python\n",
            "programs\n",
            "Working\n",
            "corpora\n",
            "categorizing\n",
            "text\n",
            "analyzing\n",
            "linguistic\n",
            "structure\n",
            "The\n",
            "online\n",
            "version\n",
            "book\n",
            "updated\n",
            "Python\n",
            "3\n",
            "NLTK\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEMMING\n",
        "from nltk.stem import PorterStemmer,RegexpStemmer,LancasterStemmer,SnowballStemmer"
      ],
      "metadata": {
        "id": "Uj8QR9DUnpz9"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=LancasterStemmer()\n",
        "R=RegexpStemmer('ing$|s$|e$|able$',min=4)\n",
        "p=PorterStemmer()\n",
        "s=SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "zRgRlFNmoDUw"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.stem('changing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vbraAYAGoorG",
        "outputId": "37c55c95-5857-4da0-c1e1-3ba360a20357"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chang'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R.stem('changing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cqXV29zPosAJ",
        "outputId": "c9460648-f86d-46a0-a9c7-d0871b97cf51"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chang'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.stem('changing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "86Zscle3ovAb",
        "outputId": "9e73fc7a-a827-40d4-e909-3cb18d303792"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chang'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.stem('changing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B-tQx03joxeF",
        "outputId": "1bff32d6-ceb6-4657-963a-9f262bc6f3ee"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chang'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LEMMANIZATION\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer  #WordNetLemmatizer default noun  samajh ke kaam karta hai, or it gives the same meaning of that word.\n",
        "wl=WordNetLemmatizer()\n",
        "wl.lemmatize('mice')\n",
        "# \"mice\" = plural noun\n",
        "#  Dictionary mein noun form \"mouse\" exist karti hai\n",
        "#  Is liye correct output → mouse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5uENXRDZo0Fp",
        "outputId": "e1f55c6a-9218-4bab-9b27-4f0b31b392a6"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mouse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wl.lemmatize('studying')\n",
        "# \"studying\" noun nahi hai\n",
        "# Verb hai (present participle)\n",
        "# As noun → WordNet mein koi base form nahi\n",
        "#  Is liye output same word return hota ha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hRO13D6Usx_J",
        "outputId": "fba465b1-123f-4a46-9778-92d1c3a1989c"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'studying'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wl.lemmatize('helo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iYAe7Xv-uQfG",
        "outputId": "c9812d9e-53bd-4216-b72b-d17774a17c27"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'helo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=\"Lies travel faster than the truth,\" \"Good taste is for people who can't afford sapphires, and warnings such as , Don't fuck with the Peaky Blinders\""
      ],
      "metadata": {
        "id": "Vzg44C0-usA2"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "wt=word_tokenize(y)\n",
        "wt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c2TF3aHr1IaJ",
        "outputId": "7596672a-655c-436c-9474-59dc90da4ab6"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Lies',\n",
              " 'travel',\n",
              " 'faster',\n",
              " 'than',\n",
              " 'the',\n",
              " 'truth',\n",
              " ',',\n",
              " 'Good',\n",
              " 'taste',\n",
              " 'is',\n",
              " 'for',\n",
              " 'people',\n",
              " 'who',\n",
              " 'ca',\n",
              " \"n't\",\n",
              " 'afford',\n",
              " 'sapphires',\n",
              " ',',\n",
              " 'and',\n",
              " 'warnings',\n",
              " 'such',\n",
              " 'as',\n",
              " ',',\n",
              " 'Do',\n",
              " \"n't\",\n",
              " 'fuck',\n",
              " 'with',\n",
              " 'the',\n",
              " 'Peaky',\n",
              " 'Blinders']"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# N-GRAMS\n",
        "from nltk.collocations import BigramCollocationFinder,TrigramCollocationFinder,ngrams\n",
        "b=BigramCollocationFinder.from_words(wt)\n",
        "t=TrigramCollocationFinder.from_words(wt)\n"
      ],
      "metadata": {
        "id": "r5Lb8n_u1PMX"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b.ngram_fd  # ngram_fd = n-gram frequency distribution\n",
        "\n",
        "# ngrams → sirf generate karta hai\n",
        "# CollocationFinder → frequency + scoring (PMI, chi-square) ke liye use hota hai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmZxVjMF14Qb",
        "outputId": "5a6eedfc-034c-4f13-eb98-bb67eecb6e9f"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('Lies', 'travel'): 1, ('travel', 'faster'): 1, ('faster', 'than'): 1, ('than', 'the'): 1, ('the', 'truth'): 1, ('truth', ','): 1, (',', 'Good'): 1, ('Good', 'taste'): 1, ('taste', 'is'): 1, ('is', 'for'): 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.ngram_fd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGTL5bHK1_rF",
        "outputId": "7e09d25e-885f-4ff3-ad35-099d41a0bb55"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('Lies', 'travel', 'faster'): 1, ('travel', 'faster', 'than'): 1, ('faster', 'than', 'the'): 1, ('than', 'the', 'truth'): 1, ('the', 'truth', ','): 1, ('truth', ',', 'Good'): 1, (',', 'Good', 'taste'): 1, ('Good', 'taste', 'is'): 1, ('taste', 'is', 'for'): 1, ('is', 'for', 'people'): 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.ngram_fd.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDT9Qk0z3O42",
        "outputId": "3ba9a09b-029f-4b54-e332-d4f4af0efee5"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([('Lies', 'travel', 'faster'), ('travel', 'faster', 'than'), ('faster', 'than', 'the'), ('than', 'the', 'truth'), ('the', 'truth', ','), ('truth', ',', 'Good'), (',', 'Good', 'taste'), ('Good', 'taste', 'is'), ('taste', 'is', 'for'), ('is', 'for', 'people'), ('for', 'people', 'who'), ('people', 'who', 'ca'), ('who', 'ca', \"n't\"), ('ca', \"n't\", 'afford'), (\"n't\", 'afford', 'sapphires'), ('afford', 'sapphires', ','), ('sapphires', ',', 'and'), (',', 'and', 'warnings'), ('and', 'warnings', 'such'), ('warnings', 'such', 'as'), ('such', 'as', ','), ('as', ',', 'Do'), (',', 'Do', \"n't\"), ('Do', \"n't\", 'fuck'), (\"n't\", 'fuck', 'with'), ('fuck', 'with', 'the'), ('with', 'the', 'Peaky'), ('the', 'Peaky', 'Blinders')])"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=ngrams(wt,3)\n",
        "for i in n:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iIKapNeR38mS",
        "outputId": "7662b4a5-5e3a-4e9d-d9a4-ea24dd3e0c81"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Lies', 'travel', 'faster')\n",
            "('travel', 'faster', 'than')\n",
            "('faster', 'than', 'the')\n",
            "('than', 'the', 'truth')\n",
            "('the', 'truth', ',')\n",
            "('truth', ',', 'Good')\n",
            "(',', 'Good', 'taste')\n",
            "('Good', 'taste', 'is')\n",
            "('taste', 'is', 'for')\n",
            "('is', 'for', 'people')\n",
            "('for', 'people', 'who')\n",
            "('people', 'who', 'ca')\n",
            "('who', 'ca', \"n't\")\n",
            "('ca', \"n't\", 'afford')\n",
            "(\"n't\", 'afford', 'sapphires')\n",
            "('afford', 'sapphires', ',')\n",
            "('sapphires', ',', 'and')\n",
            "(',', 'and', 'warnings')\n",
            "('and', 'warnings', 'such')\n",
            "('warnings', 'such', 'as')\n",
            "('such', 'as', ',')\n",
            "('as', ',', 'Do')\n",
            "(',', 'Do', \"n't\")\n",
            "('Do', \"n't\", 'fuck')\n",
            "(\"n't\", 'fuck', 'with')\n",
            "('fuck', 'with', 'the')\n",
            "('with', 'the', 'Peaky')\n",
            "('the', 'Peaky', 'Blinders')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "l=['End is the Beginning End ok', 'Beginning is the End']\n",
        "df=pd.DataFrame({'Text':l})\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "mJ1rRaCm4qdJ",
        "outputId": "7cc8bcc0-520d-410d-864f-bca60835e3a8"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Text\n",
              "0  End is the Beginning End ok\n",
              "1         Beginning is the End"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f7d31ca-69f3-48a8-b8c7-077e6564e9fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>End is the Beginning End ok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beginning is the End</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f7d31ca-69f3-48a8-b8c7-077e6564e9fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f7d31ca-69f3-48a8-b8c7-077e6564e9fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f7d31ca-69f3-48a8-b8c7-077e6564e9fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_f771c0cb-11a7-4a65-b1c5-819d64e505bd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f771c0cb-11a7-4a65-b1c5-819d64e505bd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Beginning is the End\",\n          \"End is the Beginning End ok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#COUNT VECTORIZER\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#❌ CountVectorizer = Binary presence\n",
        "#✅ CountVectorizer = Frequency count\n",
        "cv=CountVectorizer() #means how many times a word appeared in list of sentences\n",
        "#Vocabulary banata hai (poori dataset se) in alphabetical order\n",
        "#CountVectorizer dono sentences ko combine karke unique words nikalta hai"
      ],
      "metadata": {
        "id": "Mmj8-fEw8G6m"
      },
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data=cv.fit_transform(df['Text']).toarray() # makes vocabulary and converts data to numeric form\n",
        "new_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gbYhjWI8yZV",
        "outputId": "070b48b8-363d-443a-fb33-47ddf25230cb"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 1, 1, 1],\n",
              "       [1, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9yeuwPnAL7o",
        "outputId": "746c93d1-3269-41ca-f946-991a71521148"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'end': 1, 'is': 2, 'the': 4, 'beginning': 0, 'ok': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word sense disambiguation\n",
        "text='\"By order of the Peaky Blinders,\" the streets belong to them\"'\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "btgXcFK0AQKs"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=lesk(word_tokenize(text),'peaky')\n",
        "l.definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FJiMTNtQFzhH",
        "outputId": "34e41359-5ba9-4df2-bbb3-acc7c785e047"
      },
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'having or as if having especially high-pitched spots'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 316
        }
      ]
    }
  ]
}